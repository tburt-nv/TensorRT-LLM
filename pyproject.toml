####################################################################################################
###############################  BUILD CONFIGURATION  ##############################################
####################################################################################################
[build-system]
requires = ["setuptools >= 64", "pip >= 24"]
build-backend = "setuptools.build_meta"

####################################################################################################
###############################  PROJECT DATA  #####################################################
####################################################################################################
[project]
name = "tensorrt_llm"
dynamic = ["version", "description", "readme", "license", "authors", "keywords", "classifiers", "scripts"]
requires-python = ">=3.7, <4"
dependencies = [
    "accelerate>=1.7.0",
    "build",
    "colored",
    "cuda-python>=12,<13",
    "diffusers>=0.27.0",
    "lark",
    "mpi4py",
    "numpy<2",
    "onnx>=1.18.0",
    "onnx_graphsurgeon>=0.5.2",
    "openai",
    "polygraphy",
    "psutil",
    "nvidia-ml-py>=12,<13",
    # Just a wrapper since nvidia-modelopt requires pynvml
    "pynvml==12.0.0",
    "pulp",
    "pandas",
    "h5py==3.12.1",
    "StrEnum",
    "sentencepiece>=0.1.99",
    "tensorrt~=10.11.0",
    # https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/rel-25-06.html#rel-25-06 uses 2.8.0a0.
    "torch>=2.7.1,<=2.8.0a0",
    "torchvision",
    "nvidia-modelopt[torch]~=0.33.0",
    "nvidia-nccl-cu12",
    "nvidia-cuda-nvrtc-cu12",
    "transformers==4.55.0",
    "prometheus_client",
    "prometheus_fastapi_instrumentator",
    "pydantic>=2.9.1",
    "pydantic-settings[yaml]",
    "omegaconf",
    "pillow==10.3.0",
    "wheel<=0.45.1",
    "optimum",
    # evaluate needs datasets>=2.0.0 which triggers datasets>3.1.0 which is not stable: https://github.com/huggingface/datasets/issues/7467
    "datasets==3.1.0",
    "evaluate",
    "mpmath>=1.3.0",
    "click",
    "click_option_group",
    "aenum",
    "pyzmq",
    "fastapi==0.115.4",
    "uvicorn",
    "setuptools<80",
    "ordered-set",
    "peft",
    "einops",
    "flashinfer-python==0.2.5",
    "opencv-python-headless",
    "xgrammar==0.1.21",
    "llguidance==0.7.29",
    "jsonschema",
    "backoff",
    "nvtx",
    # FIXME: matplotlib is added to make nvtx happy
    "matplotlib",
    "meson",
    "ninja",
    "etcd3",
    "blake3",
    "soundfile",
    "triton==3.3.1; platform_machine == 'x86_64'",
    "tiktoken",
    "blobfile",
    "openai-harmony==0.0.4",
    "protobuf>=4.25.8",
]

[project.optional-dependencies]
devel = [
    "einops",
    "graphviz",
    "mypy",
    "mako",
    "oyaml",
    "parameterized",
    "pre-commit",
    "pybind11",
    "pybind11-stubgen",
    "pytest",
    "pytest-asyncio",
    "pytest-cov",
    "pytest-csv",
    "pytest-env",
    "pytest-forked",
    "pytest-xdist",
    "pytest-timeout",
    "pytest-split",
    "pytest-mock",
    "pytest-threadleak",
    "rouge_score",
    "cloudpickle",
    "typing-extensions==4.12.2",
    "bandit==1.7.7",
    "jsonlines==4.0.0",
    "jieba==0.42.1",
    "rouge==1.0.1",
    "pytest-rerunfailures",
    "ruff==0.9.4",
    "lm_eval[api]==0.4.8",
    "docstring_parser",
    "genai-perf==0.0.13"
]

####################################################################################################
###############################  SETUPTOOLS CONFIGURATION ##########################################
####################################################################################################
[tool.setuptools.dynamic]
version = {attr = "tensorrt_llm.version.__version__"}

####################################################################################################
###############################  UV CONFIGURATION ##################################################
####################################################################################################
[tool.uv]
managed = true
environments = [
    "python_full_version >= '3.10' and python_full_version < '4'"
]

[[tool.uv.index]]
name = "pypi"
url = "https://pypi.org/simple"

[[tool.uv.index]]
name = "torch-cu128"
url = "https://download.pytorch.org/whl/cu128"

[tool.uv.sources]
torch = { index = "torch-cu128" }

####################################################################################################
###############################  LINTING, FORMATTING AND TESTING CONFIGURATION  ####################
####################################################################################################
[tool.isort]
line_length = 80
# This should match the `include` in `[tool.ruff]`. See the comments in that section for why this
# is necessary.
extend_skip_glob = [
    "**/auto_deploy/**",
    "tensorrt_llm/_common.py",
    "tensorrt_llm/_dlpack_utils.py",
    "tensorrt_llm/_ipc_utils.py",
    "tensorrt_llm/_mnnvl_utils.py",
    "tensorrt_llm/_torch/models/modeling_pixtral.py",
    "tensorrt_llm/disaggregated_params.py",
    "tensorrt_llm/engine.py",
    "tensorrt_llm/graph_rewriting.py",
    "tensorrt_llm/logger.py",
    "tensorrt_llm/lora_manager.py",
    "tensorrt_llm/module.py",
    "tensorrt_llm/moe_config.py",
    "tensorrt_llm/profiler.py",
    "tensorrt_llm/prompt_adapter_manager.py",
    "tensorrt_llm/python_plugin.py",
    "tensorrt_llm/sampling_params.py",
    "tensorrt_llm/top_model_mixin.py",
    "tests/unittest/_torch/modeling/test_modeling_mistral.py",
    "tests/unittest/_torch/modeling/test_modeling_pixtral.py",
    "tests/unittest/_torch/models/checkpoints/hf/test_weight_loader.py",
]

[tool.yapf]
based_on_style = "pep8"
column_limit = 80

[tool.yapfignore]
# This should match the `include` in `[tool.ruff]`. See the comments in that section for why this
# is necessary.
ignore_patterns = [
    "**/auto_deploy/**",
    "tensorrt_llm/_common.py",
    "tensorrt_llm/_dlpack_utils.py",
    "tensorrt_llm/_ipc_utils.py",
    "tensorrt_llm/_mnnvl_utils.py",
    "tensorrt_llm/_torch/models/modeling_pixtral.py",
    "tensorrt_llm/disaggregated_params.py",
    "tensorrt_llm/engine.py",
    "tensorrt_llm/graph_rewriting.py",
    "tensorrt_llm/logger.py",
    "tensorrt_llm/lora_manager.py",
    "tensorrt_llm/module.py",
    "tensorrt_llm/moe_config.py",
    "tensorrt_llm/profiler.py",
    "tensorrt_llm/prompt_adapter_manager.py",
    "tensorrt_llm/python_plugin.py",
    "tensorrt_llm/sampling_params.py",
    "tensorrt_llm/top_model_mixin.py",
    "tests/unittest/_torch/modeling/test_modeling_mistral.py",
    "tests/unittest/_torch/modeling/test_modeling_pixtral.py",
    "tests/unittest/_torch/models/checkpoints/hf/test_weight_loader.py",
]

[tool.codespell]
skip = ".git,3rdparty,tests/integration/test_input_files**,**.jsonl,**.json"
exclude-file = "examples/models/core/whisper/tokenizer.py"
ignore-words-list = "rouge,inout,atleast,strat,nd,subtile,thrid,improbe,NotIn,te,iteract,anythin,tru,Tracin,vEw,dOut"

[tool.autoflake]
in-place = true
remove_all_unused_imports = true
remove_unused_variables = true
# This should match the `include` in `[tool.ruff]`. See the comments in that section for why this
# is necessary.
exclude = [
    "**/auto_deploy/**",
    "tensorrt_llm/_common.py",
    "tensorrt_llm/_dlpack_utils.py",
    "tensorrt_llm/_ipc_utils.py",
    "tensorrt_llm/_mnnvl_utils.py",
    "tensorrt_llm/_torch/models/modeling_pixtral.py",
    "tensorrt_llm/disaggregated_params.py",
    "tensorrt_llm/engine.py",
    "tensorrt_llm/graph_rewriting.py",
    "tensorrt_llm/logger.py",
    "tensorrt_llm/lora_manager.py",
    "tensorrt_llm/module.py",
    "tensorrt_llm/moe_config.py",
    "tensorrt_llm/profiler.py",
    "tensorrt_llm/prompt_adapter_manager.py",
    "tensorrt_llm/python_plugin.py",
    "tensorrt_llm/sampling_params.py",
    "tensorrt_llm/top_model_mixin.py",
    "tests/unittest/_torch/modeling/test_modeling_mistral.py",
    "tests/unittest/_torch/modeling/test_modeling_pixtral.py",
    "tests/unittest/_torch/models/checkpoints/hf/test_weight_loader.py",
]


####################################################################################################
#########################  AUTO DEPLOY LINTING AND TESTING CONFIGURATION  ##########################
####################################################################################################
[tool.ruff]
line-length = 100 # Line length limit for code
fix = true
include = [
    # all pyproject.toml files
    "**/pyproject.toml",
    # standard include of ruff restricted to auto_deploy folders
    "**/auto_deploy/**/*.py",
    "**/auto_deploy/**/*.pyi",
    "**/auto_deploy/**/*.ipynb",
    # Progressively enable ruff on all the repo to keep individual changes reasonably-sized, and
    # keep merge conflicts manageable.
    # Since keeping both `yapf` and `ruff` makes no sense (given that their formatting philosophies
    # are quite different), we should move towards removing one in favor of the other. ruff's
    # formatting mirrors black's, and both are much more widely adopted than yapf. ruff is also
    # orders of magnitude faster, so we should move to deprecate `yapf`.
    # In the transition period, we should keep the `ignore_patterns` in `[tool.yapfignore]` in sync
    # with the below, so that both pre-commit hooks can complete successfully.
    "tensorrt_llm/_common.py",
    "tensorrt_llm/_dlpack_utils.py",
    "tensorrt_llm/_ipc_utils.py",
    "tensorrt_llm/_mnnvl_utils.py",
    "tensorrt_llm/_torch/models/modeling_pixtral.py",
    "tensorrt_llm/disaggregated_params.py",
    "tensorrt_llm/engine.py",
    "tensorrt_llm/graph_rewriting.py",
    "tensorrt_llm/logger.py",
    "tensorrt_llm/lora_manager.py",
    "tensorrt_llm/module.py",
    "tensorrt_llm/moe_config.py",
    "tensorrt_llm/profiler.py",
    "tensorrt_llm/prompt_adapter_manager.py",
    "tensorrt_llm/python_plugin.py",
    "tensorrt_llm/sampling_params.py",
    "tensorrt_llm/top_model_mixin.py",
    "tests/unittest/_torch/modeling/test_modeling_mistral.py",
    "tests/unittest/_torch/modeling/test_modeling_pixtral.py",
    "tests/unittest/_torch/models/checkpoints/hf/test_weight_loader.py",
]
exclude = [
    "**3rdparty/**",
]


[tool.ruff.format]
# Like Black, respect magic trailing commas.
skip-magic-trailing-comma = false
docstring-code-format = true
# Set the line length limit used when formatting code snippets in docstrings.
docstring-code-line-length = "dynamic"


[tool.ruff.lint]
# See available rules at https://docs.astral.sh/ruff/rules/
# Flake8 is equivalent to pycodestyle + pyflakes + mccabe.
select = [
    "D", # pydocstyle --> enforcing correct docstrings for existing docstrings
    "E", # pycodestyle errors
    "F", # pyflakes
    "I", # isort
    # "N",   # pep8 naming # no naming convention enforced for now the reduce the burden
    "PLE", # pylint errors
    "W",   # pycodestyle warnings
]
extend-ignore = [
    # we don't enforce writing docstrings for public code to reduce the burden
    "D100",
    "D101",
    "D102",
    "D103",
    "D104",
    "D105",
    "D106",
    "D107",
    "D417",
]


[tool.ruff.lint.per-file-ignores]
"__init__.py" = ["F401", "F403"]
"tests/_torch/auto_deploy/*" = ["D", "E402"]
"*/_[a-zA-Z]*" = ["D"]                       # Private packages (_abc/*.py) or modules (_xyz.py)


[tool.ruff.lint.pycodestyle]
max-line-length = 120 # Line length limit for comments and docstrings


[tool.ruff.lint.pydocstyle]
convention = "google"


[tool.ruff.lint.isort]
known-first-party = ["tensorrt_llm"]
split-on-trailing-comma = false


[tool.ruff.lint.pylint]
max-args = 10


[tool.mypy]
files = ["**/auto_deploy/**"]
install_types = true
non_interactive = true
show_error_codes = true
disable_error_code = [
    "import",
    "assignment",
    "operator",
    "has-type",
    "var-annotated",
    "operator",
    "call-arg",
]
explicit_package_bases = true
namespace_packages = true
# strict checks
strict = true
disallow_subclassing_any = false
disallow_untyped_decorators = false
disallow_any_generics = false
disallow_untyped_calls = false
disallow_incomplete_defs = false
disallow_untyped_defs = false
warn_return_any = false
exclude = []


[[tool.mypy.overrides]]
module = ["tests.*"]
ignore_errors = true
